<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<template encoding-version="1.3">
    <description>StreamMart Clickstream Data Ingestion Flow - Reads from Kafka and writes to HDFS</description>
    <groupId>root</groupId>
    <name>StreamMart_Clickstream_Ingestion</name>
    <snippet>
        <processors>
            <!-- ConsumeKafka Processor -->
            <processor>
                <id>consume-kafka-1</id>
                <name>Consume Clickstream from Kafka</name>
                <class>org.apache.nifi.processors.kafka.pubsub.ConsumeKafka_2_6</class>
                <position x="100" y="100"/>
                <config>
                    <bulletinLevel>WARN</bulletinLevel>
                    <schedulingPeriod>0 sec</schedulingPeriod>
                    <executionNode>ALL</executionNode>
                    <penaltyDuration>30 sec</penaltyDuration>
                    <yieldDuration>1 sec</yieldDuration>
                    <runDurationMillis>0</runDurationMillis>
                    <autoTerminatedRelationships/>
                    <properties>
                        <entry>
                            <key>bootstrap.servers</key>
                            <value>${kafka.bootstrap.servers}</value>
                        </entry>
                        <entry>
                            <key>topic</key>
                            <value>streammart_clickstream</value>
                        </entry>
                        <entry>
                            <key>group.id</key>
                            <value>nifi-clickstream-consumer</value>
                        </entry>
                        <entry>
                            <key>auto.offset.reset</key>
                            <value>latest</value>
                        </entry>
                        <entry>
                            <key>security.protocol</key>
                            <value>PLAINTEXT</value>
                        </entry>
                        <entry>
                            <key>message-demarcator</key>
                            <value>\n</value>
                        </entry>
                        <entry>
                            <key>max.poll.records</key>
                            <value>10000</value>
                        </entry>
                    </properties>
                </config>
            </processor>

            <!-- EvaluateJsonPath - Extract fields -->
            <processor>
                <id>evaluate-json-1</id>
                <name>Extract JSON Fields</name>
                <class>org.apache.nifi.processors.standard.EvaluateJsonPath</class>
                <position x="300" y="100"/>
                <config>
                    <bulletinLevel>WARN</bulletinLevel>
                    <schedulingPeriod>0 sec</schedulingPeriod>
                    <properties>
                        <entry>
                            <key>Destination</key>
                            <value>flowfile-attribute</value>
                        </entry>
                        <entry>
                            <key>event_id</key>
                            <value>$.event_id</value>
                        </entry>
                        <entry>
                            <key>event_type</key>
                            <value>$.event_type</value>
                        </entry>
                        <entry>
                            <key>user_id</key>
                            <value>$.user_id</value>
                        </entry>
                        <entry>
                            <key>session_id</key>
                            <value>$.session_id</value>
                        </entry>
                        <entry>
                            <key>event_timestamp</key>
                            <value>$.event_timestamp</value>
                        </entry>
                        <entry>
                            <key>product_id</key>
                            <value>$.product_id</value>
                        </entry>
                    </properties>
                </config>
            </processor>

            <!-- RouteOnAttribute - Data Quality Check -->
            <processor>
                <id>route-attribute-1</id>
                <name>Data Quality Check</name>
                <class>org.apache.nifi.processors.standard.RouteOnAttribute</class>
                <position x="500" y="100"/>
                <config>
                    <bulletinLevel>WARN</bulletinLevel>
                    <schedulingPeriod>0 sec</schedulingPeriod>
                    <properties>
                        <entry>
                            <key>Routing Strategy</key>
                            <value>Route to Property name</value>
                        </entry>
                        <entry>
                            <key>valid</key>
                            <value>${event_id:isEmpty():not():and(${user_id:isEmpty():not()}):and(${event_type:isEmpty():not()})}</value>
                        </entry>
                    </properties>
                    <autoTerminatedRelationships>
                        <relationship>unmatched</relationship>
                    </autoTerminatedRelationships>
                </config>
            </processor>

            <!-- UpdateAttribute - Add Partition Info -->
            <processor>
                <id>update-attribute-1</id>
                <name>Add Partition Date</name>
                <class>org.apache.nifi.processors.attributes.UpdateAttribute</class>
                <position x="700" y="100"/>
                <config>
                    <bulletinLevel>WARN</bulletinLevel>
                    <schedulingPeriod>0 sec</schedulingPeriod>
                    <properties>
                        <entry>
                            <key>partition_date</key>
                            <value>${now():format('yyyy-MM-dd')}</value>
                        </entry>
                        <entry>
                            <key>partition_hour</key>
                            <value>${now():format('HH')}</value>
                        </entry>
                    </properties>
                </config>
            </processor>

            <!-- PutHDFS - Write to HDFS -->
            <processor>
                <id>put-hdfs-1</id>
                <name>Write to HDFS Raw Zone</name>
                <class>org.apache.nifi.processors.hadoop.PutHDFS</class>
                <position x="900" y="100"/>
                <config>
                    <bulletinLevel>WARN</bulletinLevel>
                    <schedulingPeriod>0 sec</schedulingPeriod>
                    <properties>
                        <entry>
                            <key>Hadoop Configuration Resources</key>
                            <value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value>
                        </entry>
                        <entry>
                            <key>Directory</key>
                            <value>/user/cloud-user/streammart-demo/raw/clickstream/date=${partition_date}/hour=${partition_hour}</value>
                        </entry>
                        <entry>
                            <key>Conflict Resolution Strategy</key>
                            <value>append</value>
                        </entry>
                        <entry>
                            <key>Compression codec</key>
                            <value>NONE</value>
                        </entry>
                        <entry>
                            <key>Block Size</key>
                            <value>128 MB</value>
                        </entry>
                        <entry>
                            <key>Replication</key>
                            <value>3</value>
                        </entry>
                    </properties>
                    <autoTerminatedRelationships>
                        <relationship>success</relationship>
                        <relationship>failure</relationship>
                    </autoTerminatedRelationships>
                </config>
            </processor>

            <!-- PutKafka - Forward to enriched topic for Flink -->
            <processor>
                <id>put-kafka-1</id>
                <name>Forward to Enriched Topic</name>
                <class>org.apache.nifi.processors.kafka.pubsub.PublishKafka_2_6</class>
                <position x="900" y="300"/>
                <config>
                    <bulletinLevel>WARN</bulletinLevel>
                    <schedulingPeriod>0 sec</schedulingPeriod>
                    <properties>
                        <entry>
                            <key>bootstrap.servers</key>
                            <value>${kafka.bootstrap.servers}</value>
                        </entry>
                        <entry>
                            <key>topic</key>
                            <value>streammart_enriched_events</value>
                        </entry>
                        <entry>
                            <key>security.protocol</key>
                            <value>PLAINTEXT</value>
                        </entry>
                        <entry>
                            <key>compression.type</key>
                            <value>snappy</value>
                        </entry>
                        <entry>
                            <key>Delivery Guarantee</key>
                            <value>Guarantee Single Node Delivery</value>
                        </entry>
                    </properties>
                    <autoTerminatedRelationships>
                        <relationship>success</relationship>
                        <relationship>failure</relationship>
                    </autoTerminatedRelationships>
                </config>
            </processor>
        </processors>

        <connections>
            <connection>
                <id>conn-1</id>
                <name></name>
                <sourceId>consume-kafka-1</sourceId>
                <destinationId>evaluate-json-1</destinationId>
                <selectedRelationships>
                    <relationship>success</relationship>
                </selectedRelationships>
            </connection>
            
            <connection>
                <id>conn-2</id>
                <name></name>
                <sourceId>evaluate-json-1</sourceId>
                <destinationId>route-attribute-1</destinationId>
                <selectedRelationships>
                    <relationship>matched</relationship>
                </selectedRelationships>
            </connection>
            
            <connection>
                <id>conn-3</id>
                <name></name>
                <sourceId>route-attribute-1</sourceId>
                <destinationId>update-attribute-1</destinationId>
                <selectedRelationships>
                    <relationship>valid</relationship>
                </selectedRelationships>
            </connection>
            
            <connection>
                <id>conn-4</id>
                <name></name>
                <sourceId>update-attribute-1</sourceId>
                <destinationId>put-hdfs-1</destinationId>
                <selectedRelationships>
                    <relationship>success</relationship>
                </selectedRelationships>
            </connection>
            
            <connection>
                <id>conn-5</id>
                <name></name>
                <sourceId>update-attribute-1</sourceId>
                <destinationId>put-kafka-1</destinationId>
                <selectedRelationships>
                    <relationship>success</relationship>
                </selectedRelationships>
            </connection>
        </connections>
    </snippet>
</template>
